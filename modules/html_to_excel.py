import pandas as pd
import os
import json
import sys
from datetime import datetime

try:
    from .settings import get
except ImportError:
    sys.path.append(os.path.dirname(__file__))
    from settings import get

def get_latest_cumulative_values(company_name, hist_df):
    try:
        company_data = hist_df[hist_df['íšŒì‚¬ëª…'] == company_name]
        if company_data.empty: return (0, 0)
        
        # Get the most recent entry (first row after sorting by date descending)
        latest_entry = company_data.iloc[0]
        
        latest_ëˆ„ì _ì´ì•¡ = latest_entry.get('ëˆ„ì _ì´ì•¡', 0)
        latest_ëˆ„ì _ì¶”ê°€ì£¼ì‹ìˆ˜ = latest_entry.get('ëˆ„ì _ì¶”ê°€ì£¼ì‹ìˆ˜', 0)
        
        # Convert to int if possible, otherwise return 0
        try:
            latest_ëˆ„ì _ì´ì•¡ = int(str(latest_ëˆ„ì _ì´ì•¡).replace(',', '')) if latest_ëˆ„ì _ì´ì•¡ else 0
        except:
            latest_ëˆ„ì _ì´ì•¡ = 0
            
        try:
            latest_ëˆ„ì _ì¶”ê°€ì£¼ì‹ìˆ˜ = int(str(latest_ëˆ„ì _ì¶”ê°€ì£¼ì‹ìˆ˜).replace(',', '')) if latest_ëˆ„ì _ì¶”ê°€ì£¼ì‹ìˆ˜ else 0
        except:
            latest_ëˆ„ì _ì¶”ê°€ì£¼ì‹ìˆ˜ = 0
        
        return (latest_ëˆ„ì _ì´ì•¡, latest_ëˆ„ì _ì¶”ê°€ì£¼ì‹ìˆ˜)
    except Exception as e:
        print(f"âš ï¸ Error getting cumulative values for {company_name}: {e}")
        return (0, 0)

def get_conversion_price_history(company_name, round_value, prc_df):
    """
    Get the conversion price change history for a company and round from PRC data
    Returns formatted string like "7,905(2024-01-08 13:07), 6,900(2024-11-06 14:12), ..."
    """
    try:
        # Filter PRC data for the specific company and round
        company_round_data = prc_df[
            (prc_df['íšŒì‚¬ëª…'] == company_name) & 
            (prc_df['íšŒì°¨'] == str(round_value))
        ]
        
        if company_round_data.empty:
            return ""
        
        # Sort by date (oldest first to show chronological progression)
        company_round_data = company_round_data.sort_values('ë‚ ì§œ', ascending=True)
        
        # Create the formatted string
        price_changes = []
        for _, row in company_round_data.iterrows():
            current_price = str(row.get('í˜„ì¬_ì „í™˜ê°€', '')).strip()
            date = str(row.get('ë‚ ì§œ', '')).strip()
            
            # Format the date (remove time if it's just 00:00)
            if ' 00:00' in date:
                date = date.replace(' 00:00', '')
            
            if current_price and current_price != 'nan' and date and date != 'nan':
                price_changes.append(f"{current_price}({date})")
        
        return ", ".join(price_changes)
    except Exception as e:
        print(f"âš ï¸ Error getting conversion price history for {company_name} {round_value}: {e}")
        return ""

def read_holdings_from_excel():
    """
    Read company names and rounds from the Holdings sheet in results.xlsx
    Returns a list of dictionaries with company names and rounds
    """
    try:
        excel_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'results.xlsx')
        
        if not os.path.exists(excel_path):
            print(f"âŒ Excel file not found at: {excel_path}")
            return []
        
        # Read the Holdings sheet
        holdings_df = pd.read_excel(excel_path, sheet_name='Holdings')
        
        if 'ê¸°ì—…ëª…' not in holdings_df.columns:
            print("âŒ 'ê¸°ì—…ëª…' column not found in Holdings sheet")
            return []
        
        # If there's a 'íšŒì°¨' column, use it; otherwise create empty list
        if 'íšŒì°¨' in holdings_df.columns:
            holdings_data = []
            for _, row in holdings_df.iterrows():
                holdings_data.append({
                    'company_name': str(row['ê¸°ì—…ëª…']).strip(),
                    'round': str(row['íšŒì°¨']).strip() if pd.notna(row['íšŒì°¨']) else ''
                })
            print(f"âœ… Successfully read {len(holdings_data)} companies with rounds from Holdings sheet")
        else:
            # Fallback: just company names without rounds
            holdings_data = []
            for _, row in holdings_df.iterrows():
                holdings_data.append({
                    'company_name': str(row['ê¸°ì—…ëª…']).strip(),
                    'round': ''
                })
            print(f"âœ… Successfully read {len(holdings_data)} companies from Holdings sheet (no rounds)")
        
        return holdings_data
        
    except Exception as e:
        print(f"âŒ Error reading Holdings sheet: {e}")
        return []

def convert_database_to_excel(use_holdings_filter=True):
    """
    Convert database JSON files to Excel format and save as results.xlsx
    If use_holdings_filter is True, only include data for companies/rounds in the Holdings sheet
    """
    try:
        # Get database files
        hist_db_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'resources', 'database_hist.json')
        prc_db_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'resources', 'database_prc.json')
        output_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'results.xlsx')
        
        # Read Holdings sheet to get valid company/round combinations
        holdings_data = []
        if use_holdings_filter:
            holdings_data = read_holdings_from_excel()
            if not holdings_data:
                print("âœ…  No Holdings data found, exporting all data")
        
        # Create filter sets for efficient lookup - STRICT round matching
        valid_combinations = set()
        if holdings_data:
            for item in holdings_data:
                company = item['company_name']
                round_val = item['round']
                if round_val and round_val.strip():
                    # Only add exact company+round combinations
                    valid_combinations.add((company, round_val.strip()))
                # If no round specified, skip this company entirely (strict matching)
        
        # Load data from JSON files
        hist_data = []
        prc_data = []
        
        # Load HIST data
        if os.path.exists(hist_db_path):
            with open(hist_db_path, 'r', encoding='utf-8') as f:
                hist_db = json.load(f)
                for company, data in hist_db.items():
                    if isinstance(data, dict) and 'data' in data:
                        for item in data['data']:
                            company_name = company
                            round_val = str(item.get('round', ''))
                            
                            # Apply Holdings filter if enabled - STRICT round matching
                            if use_holdings_filter and valid_combinations:
                                # Check if this exact company/round combination is valid
                                is_valid = (company_name, round_val) in valid_combinations
                                if not is_valid:
                                    continue
                            
                            hist_data.append({
                                'íšŒì‚¬ëª…': company_name,
                                'ë‚ ì§œ': item.get('date', ''),
                                'íšŒì°¨': round_val,
                                'ì¶”ê°€ì£¼ì‹ìˆ˜': item.get('additional_shares', ''),
                                'ë°œí–‰ê°€ì•¡': item.get('issue_price', ''),
                                'ëˆ„ì _ì¶”ê°€ì£¼ì‹ìˆ˜': 0,  # Will be recalculated properly
                                'ëˆ„ì _ì´ì•¡': 0,  # Will be recalculated properly
                                'ë°ì´í„°_íƒ€ì…': 'HIST'
                            })
        
        # Load PRC data
        if os.path.exists(prc_db_path):
            with open(prc_db_path, 'r', encoding='utf-8') as f:
                prc_db = json.load(f)
                for company, data in prc_db.items():
                    if isinstance(data, dict) and 'data' in data:
                        for item in data['data']:
                            company_name = company
                            round_val = str(item.get('round', ''))
                            
                            # Apply Holdings filter if enabled - STRICT round matching
                            if use_holdings_filter and valid_combinations:
                                # Check if this exact company/round combination is valid
                                is_valid = (company_name, round_val) in valid_combinations
                                if not is_valid:
                                    continue
                            
                            prc_data.append({
                                'íšŒì‚¬ëª…': company_name,
                                'ë‚ ì§œ': item.get('date', ''),
                                'íšŒì°¨': round_val,
                                'ì´ì „_ì „í™˜ê°€': item.get('prev_prc', ''),
                                'í˜„ì¬_ì „í™˜ê°€': item.get('issue_price', ''),
                                'ë°ì´í„°_íƒ€ì…': 'PRC'
                            })
        
        # Convert to DataFrames for sorting
        hist_df = pd.DataFrame(hist_data)
        prc_df = pd.DataFrame(prc_data)
        
        # Calculate accumulated values using robust internal table approach
        if not hist_df.empty and 'ë‚ ì§œ' in hist_df.columns and 'íšŒì‚¬ëª…' in hist_df.columns:
            from datetime import datetime
            
            def parse_date(date_str):
                try:
                    return datetime.strptime(date_str, '%Y-%m-%d %H:%M')
                except:
                    try:
                        return datetime.strptime(date_str, '%Y-%m-%d')
                    except:
                        return datetime.min
            
            # Create internal table with unique index for each entry
            internal_table = []
            
            # Convert DataFrame to internal table with unique index
            for idx, row in hist_df.iterrows():
                internal_entry = {
                    'original_index': idx,  # Keep track of original DataFrame index
                    'unique_key': idx,      # Use DataFrame index as unique identifier
                    'íšŒì‚¬ëª…': row['íšŒì‚¬ëª…'],
                    'ë‚ ì§œ': row['ë‚ ì§œ'],
                    'íšŒì°¨': row['íšŒì°¨'],
                    'ì¶”ê°€ì£¼ì‹ìˆ˜': row['ì¶”ê°€ì£¼ì‹ìˆ˜'],
                    'ë°œí–‰ê°€ì•¡': row['ë°œí–‰ê°€ì•¡'],
                    'ë°ì´í„°_íƒ€ì…': row['ë°ì´í„°_íƒ€ì…']
                }
                internal_table.append(internal_entry)
            
            # Process each company separately
            for company in hist_df['íšŒì‚¬ëª…'].unique():
                company_entries = [entry for entry in internal_table if entry['íšŒì‚¬ëª…'] == company]
                
                # Sort company entries chronologically with consistent tie-breaking
                company_entries.sort(key=lambda x: (
                    parse_date(x['ë‚ ì§œ']),
                    x['íšŒì°¨'],
                    int(str(x['ì¶”ê°€ì£¼ì‹ìˆ˜']).replace(',', '')) if str(x['ì¶”ê°€ì£¼ì‹ìˆ˜']).replace(',', '').isdigit() else 0,
                    int(str(x['ë°œí–‰ê°€ì•¡']).replace(',', '')) if str(x['ë°œí–‰ê°€ì•¡']).replace(',', '').isdigit() else 0,
                    x['unique_key']  # Final tie-breaker: unique key (original DataFrame index)
                ))
                
                # Calculate cumulative values chronologically
                cumulative_shares = 0
                cumulative_amount = 0
                
                for entry in company_entries:
                    try:
                        shares_str = str(entry['ì¶”ê°€ì£¼ì‹ìˆ˜']).strip()
                        price_str = str(entry['ë°œí–‰ê°€ì•¡']).strip()
                        
                        shares = int(shares_str.replace(',', '')) if shares_str and shares_str != 'nan' else 0
                        price = int(price_str.replace(',', '')) if price_str and price_str != 'nan' else 0
                        
                        # Add to cumulative values
                        cumulative_shares += shares
                        cumulative_amount += shares * price
                        
                        # Store cumulative values in the entry
                        entry['ëˆ„ì _ì¶”ê°€ì£¼ì‹ìˆ˜'] = cumulative_shares
                        entry['ëˆ„ì _ì´ì•¡'] = cumulative_amount
                        
                    except (ValueError, TypeError):
                        # If parsing fails, keep existing cumulative values
                        entry['ëˆ„ì _ì¶”ê°€ì£¼ì‹ìˆ˜'] = cumulative_shares
                        entry['ëˆ„ì _ì´ì•¡'] = cumulative_amount
            
            # Apply cumulative values back to the DataFrame using original index
            for entry in internal_table:
                original_idx = entry['original_index']
                hist_df.loc[original_idx, 'ëˆ„ì _ì¶”ê°€ì£¼ì‹ìˆ˜'] = entry['ëˆ„ì _ì¶”ê°€ì£¼ì‹ìˆ˜']
                hist_df.loc[original_idx, 'ëˆ„ì _ì´ì•¡'] = entry['ëˆ„ì _ì´ì•¡']
            
            # Sort for display (newest first)
            hist_df['ë‚ ì§œ_ì •ë ¬'] = pd.to_datetime(hist_df['ë‚ ì§œ'], errors='coerce')
            hist_df = hist_df.sort_values(['íšŒì‚¬ëª…', 'ë‚ ì§œ_ì •ë ¬'], ascending=[True, False]).drop('ë‚ ì§œ_ì •ë ¬', axis=1)
        
        if not prc_df.empty and 'ë‚ ì§œ' in prc_df.columns and 'íšŒì‚¬ëª…' in prc_df.columns:
            # Convert date strings to datetime for proper sorting
            prc_df['ë‚ ì§œ_ì •ë ¬'] = pd.to_datetime(prc_df['ë‚ ì§œ'], errors='coerce')
            prc_df = prc_df.sort_values(['íšŒì‚¬ëª…', 'ë‚ ì§œ_ì •ë ¬'], ascending=[True, False]).drop('ë‚ ì§œ_ì •ë ¬', axis=1)
        
        # Read existing Holdings sheet before creating new Excel file (preserve user modifications)
        existing_holdings_df = None
        try:
            if os.path.exists(output_path):
                # Read the existing Holdings sheet completely before overwriting
                existing_holdings_df = pd.read_excel(output_path, sheet_name='Holdings', engine='openpyxl')
                print(f"âœ… Found existing Holdings sheet with {len(existing_holdings_df)} rows and columns: {list(existing_holdings_df.columns)}")
        except Exception as e:
            print(f"âš ï¸ Could not read existing Holdings sheet: {e}")
        
        # Create Excel writer (mode='w' clears all existing sheets)
        with pd.ExcelWriter(output_path, engine='openpyxl', mode='w') as writer:
            # Write the preserved Holdings sheet or create new one
            if existing_holdings_df is not None:
                # Add cumulative values to existing Holdings sheet
                holdings_with_cumulative = existing_holdings_df.copy()
                
                # Add cumulative value columns if they don't exist
                if 'ëˆ„ì _ì´ì•¡' not in holdings_with_cumulative.columns:
                    holdings_with_cumulative['ëˆ„ì _ì´ì•¡'] = 0
                if 'ëˆ„ì _ì¶”ê°€ì£¼ì‹ìˆ˜' not in holdings_with_cumulative.columns:
                    holdings_with_cumulative['ëˆ„ì _ì¶”ê°€ì£¼ì‹ìˆ˜'] = 0
                if 'ì „í™˜ê°€_ë³€ë™ë‚´ì—­' not in holdings_with_cumulative.columns:
                    holdings_with_cumulative['ì „í™˜ê°€_ë³€ë™ë‚´ì—­'] = ""
                
                # Update cumulative values and conversion price history for each company
                for idx, row in holdings_with_cumulative.iterrows():
                    company_name = row.get('ê¸°ì—…ëª…', '')
                    round_value = row.get('íšŒì°¨', '')
                    if company_name:
                        latest_ëˆ„ì _ì´ì•¡, latest_ëˆ„ì _ì¶”ê°€ì£¼ì‹ìˆ˜ = get_latest_cumulative_values(company_name, hist_df)
                        holdings_with_cumulative.loc[idx, 'ëˆ„ì _ì´ì•¡'] = latest_ëˆ„ì _ì´ì•¡
                        holdings_with_cumulative.loc[idx, 'ëˆ„ì _ì¶”ê°€ì£¼ì‹ìˆ˜'] = latest_ëˆ„ì _ì¶”ê°€ì£¼ì‹ìˆ˜
                        
                        # Get conversion price history if round is specified
                        if round_value:
                            conversion_history = get_conversion_price_history(company_name, round_value, prc_df)
                            holdings_with_cumulative.loc[idx, 'ì „í™˜ê°€_ë³€ë™ë‚´ì—­'] = conversion_history
                
                holdings_with_cumulative.to_excel(writer, sheet_name='Holdings', index=False)
                print("âœ… Updated existing Holdings sheet with latest cumulative values")
            else:
                # If no existing file, create Holdings sheet from Holdings data with cumulative values
                if holdings_data:
                    holdings_df = pd.DataFrame(holdings_data)
                    # Rename columns to match expected format
                    holdings_df = holdings_df.rename(columns={'company_name': 'ê¸°ì—…ëª…', 'round': 'íšŒì°¨'})
                    
                    # Add cumulative value and conversion price history columns
                    holdings_df['ëˆ„ì _ì´ì•¡'] = 0
                    holdings_df['ëˆ„ì _ì¶”ê°€ì£¼ì‹ìˆ˜'] = 0
                    holdings_df['ì „í™˜ê°€_ë³€ë™ë‚´ì—­'] = ""
                    
                    # Update cumulative values and conversion price history for each company
                    for idx, row in holdings_df.iterrows():
                        company_name = row.get('ê¸°ì—…ëª…', '')
                        round_value = row.get('íšŒì°¨', '')
                        if company_name:
                            latest_ëˆ„ì _ì´ì•¡, latest_ëˆ„ì _ì¶”ê°€ì£¼ì‹ìˆ˜ = get_latest_cumulative_values(company_name, hist_df)
                            holdings_df.loc[idx, 'ëˆ„ì _ì´ì•¡'] = latest_ëˆ„ì _ì´ì•¡
                            holdings_df.loc[idx, 'ëˆ„ì _ì¶”ê°€ì£¼ì‹ìˆ˜'] = latest_ëˆ„ì _ì¶”ê°€ì£¼ì‹ìˆ˜
                            
                            # Get conversion price history if round is specified
                            if round_value:
                                conversion_history = get_conversion_price_history(company_name, round_value, prc_df)
                                holdings_df.loc[idx, 'ì „í™˜ê°€_ë³€ë™ë‚´ì—­'] = conversion_history
                    
                    holdings_df.to_excel(writer, sheet_name='Holdings', index=False)
                    print("âœ… Created new Holdings sheet with latest cumulative values")
                else:
                    # Fallback: create empty Holdings sheet with cumulative columns
                    empty_holdings_df = pd.DataFrame(columns=['ê¸°ì—…ëª…', 'íšŒì°¨', 'ëˆ„ì _ì´ì•¡', 'ëˆ„ì _ì¶”ê°€ì£¼ì‹ìˆ˜', 'ì „í™˜ê°€_ë³€ë™ë‚´ì—­'])
                    empty_holdings_df.to_excel(writer, sheet_name='Holdings', index=False)
                    print("âœ… Created empty Holdings sheet with cumulative columns")
            
            # Create HIST data sheet (using filtered and sorted DataFrame)
            hist_df.to_excel(writer, sheet_name='HIST_Data', index=False)
            
            # Create PRC data sheet (using filtered and sorted DataFrame)
            prc_df.to_excel(writer, sheet_name='PRC_Data', index=False)
            
            # Create summary sheet
            filter_text = 'Holdings ì‹œíŠ¸ ê¸°ì¤€ í•„í„°ë§' if use_holdings_filter else 'í•„í„° ì—†ìŒ'
            
            summary_data = {
                'í•­ëª©': [
                    'Holdings ì‹œíŠ¸ íšŒì‚¬ ìˆ˜',
                    'HIST ë°ì´í„° ê±´ìˆ˜ (í•„í„°ë§ í›„)',
                    'PRC ë°ì´í„° ê±´ìˆ˜ (í•„í„°ë§ í›„)',
                    'ì ìš©ëœ í•„í„°',
                    'ìƒì„± ì‹œê°„',
                    'ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ê²½ë¡œ'
                ],
                'ê°’': [
                    len(holdings_data),
                    len(hist_df),
                    len(prc_df),
                    filter_text,
                    datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    f'HIST: {hist_db_path}, PRC: {prc_db_path}'
                ]
            }
            summary_df = pd.DataFrame(summary_data)
            summary_df.to_excel(writer, sheet_name='Summary', index=False)
        
        filter_text = ' (Holdings ì‹œíŠ¸ ê¸°ì¤€)' if use_holdings_filter else ''
        
        return {
            'success': True,
            'message': f'Excel íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤{filter_text}. (Holdings {len(holdings_data)}ê°œ íšŒì‚¬, HIST {len(hist_df)}ê±´, PRC {len(prc_df)}ê±´)',
            'file_path': output_path,
            'companies_count': len(holdings_data),
            'hist_count': len(hist_df),
            'prc_count': len(prc_df),
            'use_holdings_filter': use_holdings_filter
        }
        
    except Exception as e:
        return {
            'success': False,
            'message': f'Excel íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {str(e)}',
            'error': str(e)
        }

def get_database_summary(company_filter=None, round_filter=None):
    """
    Get summary information about the databases with optional filtering
    """
    try:
        hist_db_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'resources', 'database_hist.json')
        prc_db_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'resources', 'database_prc.json')
        
        hist_data = []
        prc_data = []
        
        # Load HIST data
        if os.path.exists(hist_db_path):
            with open(hist_db_path, 'r', encoding='utf-8') as f:
                hist_db = json.load(f)
                for company, data in hist_db.items():
                    if isinstance(data, dict) and 'data' in data:
                        for item in data['data']:
                            hist_data.append({
                                'íšŒì‚¬ëª…': company,
                                'íšŒì°¨': item.get('round', ''),
                                'ë‚ ì§œ': item.get('date', '')
                            })
        
        # Load PRC data
        if os.path.exists(prc_db_path):
            with open(prc_db_path, 'r', encoding='utf-8') as f:
                prc_db = json.load(f)
                for company, data in prc_db.items():
                    if isinstance(data, dict) and 'data' in data:
                        for item in data['data']:
                            prc_data.append({
                                'íšŒì‚¬ëª…': company,
                                'íšŒì°¨': item.get('round', ''),
                                'ë‚ ì§œ': item.get('date', '')
                            })
        
        # Convert to DataFrames and apply filters
        hist_df = pd.DataFrame(hist_data)
        prc_df = pd.DataFrame(prc_data)
        
        if not hist_df.empty:
            if company_filter and company_filter.strip():
                hist_df = hist_df[hist_df['íšŒì‚¬ëª…'].str.contains(company_filter, na=False, case=False)]
            if round_filter and round_filter.strip():
                hist_df = hist_df[hist_df['íšŒì°¨'].astype(str).str.contains(str(round_filter), na=False, case=False)]
        
        if not prc_df.empty:
            if company_filter and company_filter.strip():
                prc_df = prc_df[prc_df['íšŒì‚¬ëª…'].str.contains(company_filter, na=False, case=False)]
            if round_filter and round_filter.strip():
                prc_df = prc_df[prc_df['íšŒì°¨'].astype(str).str.contains(str(round_filter), na=False, case=False)]
        
        hist_count = len(hist_df)
        prc_count = len(prc_df)
        companies = set(hist_df['íšŒì‚¬ëª…'].tolist() + prc_df['íšŒì‚¬ëª…'].tolist())
        
        return {
            'success': True,
            'companies_count': len(companies),
            'hist_count': hist_count,
            'prc_count': prc_count,
            'total_records': hist_count + prc_count
        }
        
    except Exception as e:
        return {
            'success': False,
            'message': f'ë°ì´í„°ë² ì´ìŠ¤ ìš”ì•½ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}',
            'error': str(e)
        }

if __name__ == '__main__':
    print("ğŸ§ª Testing HTML to Excel conversion...")
    
    # Test database summary
    summary = get_database_summary()
    print(f"âœ… Database Summary: {summary}")
    
    # Test Excel conversion
    result = convert_database_to_excel()
    print(f"ğŸ“„ Excel Conversion Result: {result}")
    
    if result['success']:
        print(f"âœ… Excel file created at: {result['file_path']}")
    else:
        print(f"âŒ Excel creation failed: {result['message']}")
